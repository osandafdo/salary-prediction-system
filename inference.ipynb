{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d1b7907",
   "metadata": {},
   "source": [
    "## Inference the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b33da1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import os\n",
    "import joblib\n",
    "from sklearn.discriminant_analysis import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fcadea3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model architecture.\n",
    "class FullyConnectedNeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "\n",
    "        #First Layer\n",
    "        self.layer_1 = nn.Linear(input_size, 128)     # Input layer to 128 neurons\n",
    "        self.activation_1 = nn.ReLU()       # ReLU activation function\n",
    "\n",
    "        # Second Layer\n",
    "        self.layer_2 = nn.Linear(128, 64)    # 128 neurons to 64 neurons\n",
    "        self.activation_2 = nn.ReLU()       # Another ReLU\n",
    "\n",
    "        # Second Layer\n",
    "        self.layer_3 = nn.Linear(64, 32)    # 64 neurons to 32 neurons\n",
    "        self.activation_3 = nn.ReLU()       # Another ReLU\n",
    "\n",
    "         # Third and the final Layer\n",
    "        self.layer_4 = nn.Linear(32, 1)     # Output layer to 1 neurons (classes)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer_1(x)\n",
    "        x = self.activation_1(x)\n",
    "\n",
    "        x = self.layer_2(x)\n",
    "        x= self.activation_2(x)\n",
    "\n",
    "        x = self.layer_3(x)\n",
    "        x= self.activation_3(x)\n",
    "\n",
    "        x = self.layer_4(x)  # Final layer does not need activation for multi-class classification\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6262a69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "def load_model(model_path, input_size):\n",
    "\n",
    "    if not os.path.exists(model_path):\n",
    "        raise FileNotFoundError(f\"Model file not found: {model_path}\")\n",
    "\n",
    "    model = FullyConnectedNeuralNetwork(input_size)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=torch.device(\"cpu\")))\n",
    "    print(\"Model loaded successfully!\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "db227325",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, input_data_tensor):\n",
    "    try:\n",
    "        # convert input data to tensor if not already\n",
    "        \n",
    "        if not isinstance(input_data_tensor, torch.Tensor):\n",
    "            input_data_tensor = torch.tensor(input_data_tensor, dtype=torch.float32)\n",
    "            print(\"Converted input data to tensor.\")  \n",
    "\n",
    "        # Later in inference stage: load scalers\n",
    "        loaded_feature_scaler = joblib.load('feature_scaler.joblib')\n",
    "        loaded_target_scaler = joblib.load('target_scaler.joblib')\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        # Perform inference (query the model)\n",
    "        with torch.no_grad(): # Use no_grad() to save memory and computations during inference\n",
    "            output = model(input_data_tensor)\n",
    "            y_pred_original = loaded_target_scaler.inverse_transform(output.reshape(-1, 1))\n",
    "\n",
    "        print(\"\\nQuerying the model with input...\")\n",
    "        print(f\"Model input: {input_data_tensor}\")\n",
    "        print(f\"Model output: Salary ${y_pred_original.item():.2f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "30a6c0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_data_for_inference(df):\n",
    "    \n",
    "    all_benefits = df[\"AdditionalBenefits\"].dropna().apply(lambda x: [b.strip() for b in str(x).split(\";\")])\n",
    "    benefits_array = [item for sublist in all_benefits for item in sublist]\n",
    "    unique_benefits = list(set(benefits_array))\n",
    "\n",
    "    # Feature engineering: Extract key benefits as binary flags\n",
    "    for benefit in unique_benefits:\n",
    "        df[benefit] = df[\"AdditionalBenefits\"].apply(lambda x: 1 if benefit in str(x) else 0)\n",
    "\n",
    "    # Drop redundant columns\n",
    "    df = df.drop(columns=[\"AdditionalBenefits\"])\n",
    "\n",
    "    # Preprocessing pipeline\n",
    "    # Categorical features will be one-hot encoded\n",
    "    # Numerical features will be scaled\n",
    "    # This is necessary for the ANN to work properly\n",
    "    categorical_columns = ['Gender', 'RemoteOnsite', 'Industry', 'Education', 'Location', 'JobTitle']\n",
    "    numerical_columns = ['ExperienceYears', 'Certifications', 'PreviousCompanies', 'Age', 'CompanySize', 'SalaryUSD']\n",
    "\n",
    "    # --------------------------\n",
    "    # 3. Encode categorical variables\n",
    "    # --------------------------\n",
    "    df = pd.get_dummies(df, columns=categorical_columns, drop_first=False)\n",
    "\n",
    "    # --------------------------\n",
    "    # 4. Scale numeric features\n",
    "    # --------------------------\n",
    "    scaler = StandardScaler()\n",
    "    df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
    "\n",
    "    # --------------------------\n",
    "    # 5. Separate features and target\n",
    "    # --------------------------\n",
    "    X = df.drop(columns=[\"SalaryUSD\"])   # Features except the salary (target variable)\n",
    "    y = df[\"SalaryUSD\"]                  # Target (regression)\n",
    "\n",
    "    print(\"Input features:\\n\", X.head().transpose())\n",
    "    print(\"Input target:\\n\", y.head().transpose())\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cc29d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data tensor shape: torch.Size([1, 41])\n",
      "Model loaded successfully!\n",
      "\n",
      "Querying the model with input...\n",
      "Model input: tensor([[ 0.6607,  0.2850,  0.7127,  0.3134, -0.5013,  0.0000,  0.0000,  1.0000,\n",
      "          0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  1.0000,  0.0000,  0.0000,\n",
      "          1.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,\n",
      "          1.0000,  1.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000]])\n",
      "Model output: Salary $87646.35\n"
     ]
    }
   ],
   "source": [
    "# model local file path\n",
    "model_path = os.path.abspath(\"optimized_model.pt\")\n",
    "\n",
    "# Define the data as a dictionary\n",
    "data = {\n",
    "    \"ExperienceYears\": 0.660729,\n",
    "    \"Certifications\": 0.285029,\n",
    "    \"PreviousCompanies\": 0.712733,\n",
    "    \"Age\": 0.313445,\n",
    "    \"CompanySize\": -0.501345,\n",
    "    \"CommuterSupport\": 0,\n",
    "    \"HealthInsurance\": 0,\n",
    "    \"FlexibleHours\": 1,\n",
    "    \"Gym\": 1,\n",
    "    \"Bonus\": 0,\n",
    "    \"StockOptions\": 0,\n",
    "    \"Retirement\": 1,\n",
    "    \"Gender_Female\": False,\n",
    "    \"Gender_Male\": True,\n",
    "    \"Gender_Non-binary\": False,\n",
    "    \"RemoteOnsite_Hybrid\": False,\n",
    "    \"RemoteOnsite_Onsite\": True,\n",
    "    \"RemoteOnsite_Remote\": False,\n",
    "    \"Industry_Consulting\": True,\n",
    "    \"Industry_Finance\": False,\n",
    "    \"Industry_Healthcare\": False,\n",
    "    \"Industry_Retail\": False,\n",
    "    \"Industry_Tech\": False,\n",
    "    \"Education_Bachelors\": True,\n",
    "    \"Education_Diploma\": True,\n",
    "    \"Education_Masters\": True,\n",
    "    \"Education_PhD\": True,\n",
    "    \"Location_Australia\": False,\n",
    "    \"Location_Germany\": False,\n",
    "    \"Location_India\": True,\n",
    "    \"Location_Sri Lanka\": False,\n",
    "    \"Location_Sweden\": False,\n",
    "    \"Location_UK\": False,\n",
    "    \"Location_USA\": False,\n",
    "    \"JobTitle_Data Engineer\": True,\n",
    "    \"JobTitle_Data Scientist\": False,\n",
    "    \"JobTitle_Fullstack Developer\": False,\n",
    "    \"JobTitle_Lead Engineer\": False,\n",
    "    \"JobTitle_Senior Software Engineer\": False,\n",
    "    \"JobTitle_Software Architect\": False,\n",
    "    \"JobTitle_Software Engineer\": False\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame([data])\n",
    "\n",
    "# Step 1: Preprocess the input data\n",
    "# input_data = preprocess_data_for_inference(df)\n",
    "# Convert DataFrame to tensor\n",
    "input_data = df.astype(float)\n",
    "input_data_tensor = torch.tensor(input_data.values, dtype=torch.float32)\n",
    "print(\"Input data tensor shape:\", input_data_tensor.shape)\n",
    "\n",
    "# Step 2: Load the model\n",
    "loaded_model = load_model(model_path, input_size=41)\n",
    "\n",
    "# Step 3: Inference\n",
    "inference(loaded_model, input_data_tensor)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
